{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "83690eea",
   "metadata": {},
   "source": [
    "# 04. The Art and Science of Data for LLMs\n",
    "\n",
    "> âš¡Compute Note: You can run this notebook on CPU. \n",
    "\n",
    "Welcome to the fourth part of our series! So far, we have built and optimized a GPT model from scratch. However, a powerful model architecture is only half of the equation. The other, arguably more important, half is the **data** it's trained on.\n",
    "\n",
    "The principle of \"garbage in, garbage out\" has never been more true than in the age of LLMs. The quality, diversity, and cleanliness of your training data directly determine your model's capabilities, its biases, and its failure modes. In this notebook, we will explore:\n",
    "\n",
    "1.  **What large-scale datasets look like**: We'll load a subset of a massive web-scraped dataset.\n",
    "2.  **Common data quality issues**: We'll inspect raw data to find boilerplate, code, and other artifacts.\n",
    "3.  **Filtering and cleaning techniques**: We'll discuss and implement simple heuristics to improve data quality.\n",
    "4.  **The impact of curation**: We'll compare our raw dataset to a highly-filtered one to see the difference.\n",
    "\n",
    "For this tutorial, we'll rely heavily on the ðŸ¤— `datasets` library, which is the standard for accessing and processing massive datasets efficiently.\n",
    "\n",
    "I highly recommend the reader to go through the [Stanford CS336 Data lectures](https://www.youtube.com/watch?v=WePxmeXU1xg&list=PLoROMvodv4rOY23Y0BoGoBGgQ1zmU_MT_&index=13)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecf2c785",
   "metadata": {},
   "source": [
    "### Setup\n",
    "\n",
    "First, let's install the necessary libraries. We need `datasets` to download and process our data, and `matplotlib` for visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2a7b5e11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: datasets in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (4.2.0)\n",
      "Requirement already satisfied: matplotlib in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (3.8.2)\n",
      "Requirement already satisfied: filelock in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from datasets) (3.19.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from datasets) (1.26.4)\n",
      "Requirement already satisfied: pyarrow>=21.0.0 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from datasets) (21.0.0)\n",
      "Requirement already satisfied: dill<0.4.1,>=0.3.0 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from datasets) (0.4.0)\n",
      "Requirement already satisfied: pandas in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from datasets) (2.1.4)\n",
      "Requirement already satisfied: requests>=2.32.2 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from datasets) (2.32.5)\n",
      "Requirement already satisfied: httpx<1.0.0 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from datasets) (0.28.1)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from datasets) (4.67.1)\n",
      "Requirement already satisfied: xxhash in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from datasets) (3.6.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2025.9.0,>=2023.1.0 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (2025.9.0)\n",
      "Requirement already satisfied: huggingface-hub<2.0,>=0.25.0 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from datasets) (0.35.3)\n",
      "Requirement already satisfied: packaging in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from datasets) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from datasets) (6.0.3)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (3.12.15)\n",
      "Requirement already satisfied: anyio in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from httpx<1.0.0->datasets) (4.11.0)\n",
      "Requirement already satisfied: certifi in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from httpx<1.0.0->datasets) (2025.8.3)\n",
      "Requirement already satisfied: httpcore==1.* in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from httpx<1.0.0->datasets) (1.0.9)\n",
      "Requirement already satisfied: idna in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from httpx<1.0.0->datasets) (3.10)\n",
      "Requirement already satisfied: h11>=0.16 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from httpcore==1.*->httpx<1.0.0->datasets) (0.16.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from huggingface-hub<2.0,>=0.25.0->datasets) (4.15.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from huggingface-hub<2.0,>=0.25.0->datasets) (1.1.10)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from matplotlib) (1.3.3)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from matplotlib) (4.60.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from matplotlib) (1.4.9)\n",
      "Requirement already satisfied: pillow>=8 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from matplotlib) (11.3.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from matplotlib) (3.2.5)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (1.7.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (6.6.4)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (0.3.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (1.20.1)\n",
      "Requirement already satisfied: six>=1.5 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from requests>=2.32.2->datasets) (3.4.3)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from requests>=2.32.2->datasets) (2.5.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from anyio->httpx<1.0.0->datasets) (1.3.1)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from pandas->datasets) (2025.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install datasets matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e7724b3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datasets\n",
    "from datasets import load_dataset\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "\n",
    "# Set default figure size for plots\n",
    "plt.rcParams['figure.figsize'] = (10, 6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "039d221e",
   "metadata": {},
   "source": [
    "### 1. Exploring a Raw Web Dataset: C4\n",
    "\n",
    "The **Colossal Cleaned Common Crawl (C4)** dataset was created by Google for training their T5 models. It's a massive scrape of the public internet, which has undergone some basic cleaning (like removing offensive words and deduplication). However, it's still considered relatively \"raw\" compared to more modern, heavily curated datasets.\n",
    "\n",
    "Let's load a small part of the C4 dataset to see what it looks like. We'll use `streaming=True` to avoid downloading the entire dataset, which is several terabytes!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21ed0dd6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5cbefbd3c6fa476e97de1ee26d7c7322",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/1024 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "454c7796fbf34b2d84c74ffd1afe599f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/1024 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Raw C4 Dataset Examples ---\n",
      "\n",
      "--- Example 1 ---\n",
      "Beginners BBQ Class Taking Place in Missoula!\n",
      "Do you want to get better at making delicious BBQ? You will have the opportunity, put this on your calendar now. Thursday, September 22nd join World Class BBQ Champion, Tony Balay from Lonestar Smoke Rangers. He will be teaching a beginner level class for everyone who wants to get better with their culinary skills.\n",
      "He will teach you everything you need to know to compete in a KCBS BBQ competition, including techniques, recipes, timelines, meat select\n",
      "\n",
      "--- Example 2 ---\n",
      "Discussion in 'Mac OS X Lion (10.7)' started by axboi87, Jan 20, 2012.\n",
      "I've got a 500gb internal drive and a 240gb SSD.\n",
      "When trying to restore using disk utility i'm given the error \"Not enough space on disk ____ to restore\"\n",
      "But I shouldn't have to do that!!!\n",
      "Any ideas or workarounds before resorting to the above?\n",
      "Use Carbon Copy Cloner to copy one drive to the other. I've done this several times going from larger HDD to smaller SSD and I wound up with a bootable SSD drive. One step you have to \n",
      "\n",
      "--- Example 3 ---\n",
      "Foil plaid lycra and spandex shortall with metallic slinky insets. Attached metallic elastic belt with O-ring. Headband included. Great hip hop or jazz dance costume. Made in the USA.\n",
      "\n",
      "--- Example 4 ---\n",
      "How many backlinks per day for new site?\n",
      "Discussion in 'Black Hat SEO' started by Omoplata, Dec 3, 2010.\n",
      "1) for a newly created site, what's the max # backlinks per day I should do to be safe?\n",
      "2) how long do I have to let my site age before I can start making more blinks?\n",
      "I did about 6000 forum profiles every 24 hours for 10 days for one of my sites which had a brand new domain.\n",
      "There is three backlinks for every of these forum profile so thats 18 000 backlinks every 24 hours and nothing happene\n",
      "\n",
      "--- Example 5 ---\n",
      "The Denver Board of Education opened the 2017-18 school year with an update on projects that include new construction, upgrades, heat mitigation and quality learning environments.\n",
      "We are excited that Denver students will be the beneficiaries of a four year, $572 million General Obligation Bond. Since the passage of the bond, our construction team has worked to schedule the projects over the four-year term of the bond.\n",
      "Denver voters on Tuesday approved bond and mill funding measures for students \n"
     ]
    }
   ],
   "source": [
    "# Load the C4 dataset in streaming mode\n",
    "c4_dataset = load_dataset(\"allenai/c4\", \"en\", streaming=True, split='train')\n",
    "\n",
    "# Let's look at the first few examples\n",
    "print(\"--- Raw C4 Dataset Examples ---\")\n",
    "for i, example in enumerate(iter(c4_dataset.take(5))):\n",
    "    print(f\"\\n--- Example {i+1} ---\")\n",
    "    # Print the first 500 characters of the text\n",
    "    print(example['text'][:500])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21ed0dd6",
   "metadata": {},
   "source": [
    "### 2. Identifying Data Quality Issues\n",
    "\n",
    "As you look through the examples above, you might notice some problems:\n",
    "- **Boilerplate Text**: Phrases like \"log in,\" \"terms of use,\" or cookie consent notices.\n",
    "- **Code and Markup**: Snippets of JavaScript, HTML, or CSS that are not natural language.\n",
    "- **Strange Formatting**: Excessive line breaks, weird characters, or garbled text.\n",
    "- **Non-Prose Content**: Lists, tables, or other structured data that doesn't read like a book.\n",
    "\n",
    "Training a model on this kind of data can teach it to generate undesirable content. Our goal is to filter the dataset to keep only high-quality, natural language prose."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d206006b",
   "metadata": {},
   "source": [
    "### 3. Data Filtering Techniques\n",
    "\n",
    "Data filtering is a deep and complex field, but we can apply some simple yet powerful heuristics. Here are a few common ones:\n",
    "\n",
    "1.  **Length Filtering**: Remove documents that are too short or too long.\n",
    "2.  **Character Filtering**: Remove documents with a high percentage of non-alphanumeric characters.\n",
    "3.  **Boilerplate Removal**: Remove documents containing common web boilerplate phrases (e.g., \"JavaScript is disabled\").\n",
    "4.  **Repetition Removal**: Remove documents with highly repetitive lines or n-grams.\n",
    "\n",
    "Let's create a simple filtering function that combines a few of these ideas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e52fa9b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Filtered C4 Dataset Examples ---\n",
      "\n",
      "--- Example 1 ---\n",
      "Beginners BBQ Class Taking Place in Missoula!\n",
      "Do you want to get better at making delicious BBQ? You will have the opportunity, put this on your calendar now. Thursday, September 22nd join World Class BBQ Champion, Tony Balay from Lonestar Smoke Rangers. He will be teaching a beginner level class for everyone who wants to get better with their culinary skills.\n",
      "He will teach you everything you need to know to compete in a KCBS BBQ competition, including techniques, recipes, timelines, meat select\n",
      "\n",
      "--- Example 2 ---\n",
      "Discussion in 'Mac OS X Lion (10.7)' started by axboi87, Jan 20, 2012.\n",
      "I've got a 500gb internal drive and a 240gb SSD.\n",
      "When trying to restore using disk utility i'm given the error \"Not enough space on disk ____ to restore\"\n",
      "But I shouldn't have to do that!!!\n",
      "Any ideas or workarounds before resorting to the above?\n",
      "Use Carbon Copy Cloner to copy one drive to the other. I've done this several times going from larger HDD to smaller SSD and I wound up with a bootable SSD drive. One step you have to \n",
      "\n",
      "--- Example 3 ---\n",
      "How many backlinks per day for new site?\n",
      "Discussion in 'Black Hat SEO' started by Omoplata, Dec 3, 2010.\n",
      "1) for a newly created site, what's the max # backlinks per day I should do to be safe?\n",
      "2) how long do I have to let my site age before I can start making more blinks?\n",
      "I did about 6000 forum profiles every 24 hours for 10 days for one of my sites which had a brand new domain.\n",
      "There is three backlinks for every of these forum profile so thats 18 000 backlinks every 24 hours and nothing happene\n",
      "\n",
      "--- Example 4 ---\n",
      "The Denver Board of Education opened the 2017-18 school year with an update on projects that include new construction, upgrades, heat mitigation and quality learning environments.\n",
      "We are excited that Denver students will be the beneficiaries of a four year, $572 million General Obligation Bond. Since the passage of the bond, our construction team has worked to schedule the projects over the four-year term of the bond.\n",
      "Denver voters on Tuesday approved bond and mill funding measures for students \n",
      "\n",
      "--- Example 5 ---\n",
      "BANGALORE CY JUNCTION SBC to GONDIA JUNCTION G train timings, routes, stops, and complete info.\n",
      "As of now, 1 trains run between from BANGALORE CY JUNCTION (YPR) to GONDIA JUNCTION (G).\n",
      "The fastest train from BANGALORE CY JUNCTION (YPR) to GONDIA JUNCTION (G) is YPR KRBA WAINGANGA EXP (12251) that departs at 23:40 and arrives to at 21:15. It takes approximately 21:35 hours.\n"
     ]
    }
   ],
   "source": [
    "def is_high_quality(example):\n",
    "    \"\"\"A simple heuristic-based filter for data quality.\"\"\"\n",
    "    text = example['text']\n",
    "    \n",
    "    # 1. Length filter\n",
    "    if len(text) < 200 or len(text) > 100000:\n",
    "        return False\n",
    "    \n",
    "    # 2. Boilerplate filter\n",
    "    boilerplate_phrases = [\n",
    "        \"terms of use\", \"privacy policy\", \"cookie policy\", \n",
    "        \"subscribe to our newsletter\", \"enable javascript\"\n",
    "    ]\n",
    "    if any(phrase in text.lower() for phrase in boilerplate_phrases):\n",
    "        return False\n",
    "        \n",
    "    # 3. Character filter (check for high proportion of non-alphanumeric chars)\n",
    "    # This can be a proxy for code or heavily formatted text\n",
    "    alphanumeric_chars = sum(c.isalnum() for c in text)\n",
    "    if alphanumeric_chars / len(text) < 0.75:\n",
    "        return False\n",
    "        \n",
    "    return True\n",
    "\n",
    "# The .filter() method applies our function to each example\n",
    "filtered_c4 = c4_dataset.filter(is_high_quality)\n",
    "\n",
    "print(\"--- Filtered C4 Dataset Examples ---\")\n",
    "for i, example in enumerate(iter(filtered_c4.take(5))):\n",
    "    print(f\"\\n--- Example {i+1} ---\")\n",
    "    print(example['text'][:500])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a7f3836",
   "metadata": {},
   "source": [
    "While our simple filter helps, professional dataset creation involves much more sophisticated pipelines. Let's look at a dataset that has already undergone this process."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6dc1df0",
   "metadata": {},
   "source": [
    "### 4. A Look at a Highly Curated Dataset: FineWeb\n",
    "\n",
    "**FineWeb**, created by the Hugging Face team, is a great example of a state-of-the-art, highly filtered dataset. It starts from Common Crawl but applies a rigorous filtering and deduplication pipeline, resulting in over 15 trillion tokens of high-quality text.\n",
    "\n",
    "Let's load a sample of FineWeb and compare it to the raw C4 examples.\n",
    "\n",
    "I also recommend going through the description of the fineweb to get an idea of how the quality is assessed for production datasets. \n",
    "Reference: https://huggingface.co/datasets/HuggingFaceFW/fineweb-edu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "84faba50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "42db19c6343b4dcabd08cad638008d0b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/2410 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- FineWeb Dataset Examples ---\n",
      "\n",
      "--- Example 1 ---\n",
      "The Independent Jane\n",
      "For all the love, romance and scandal in Jane Austenâ€™s books, what they are really about is freedom and independence. Independence of thought and the freedom to choose.\n",
      "Elizabethâ€™s refusal of Mr. Collins offer of marriage showed an independence seldom seen in heroines of the day. Her refusal of Mr. Darcy while triggered by anger showed a level of independence that left him shocked and stunned.\n",
      "The freedom she exhibited in finally accepting him in direct defiance of Lady Cath\n",
      "\n",
      "--- Example 2 ---\n",
      "Taking Play Seriously\n",
      "By ROBIN MARANTZ HENIG\n",
      "Published: February 17, 2008\n",
      "On a drizzly Tuesday night in late January, 200 people came out to hear a psychiatrist talk rhapsodically about play -- not just the intense, joyous play of children, but play for all people, at all ages, at all times. (All species too; the lecture featured touching photos of a polar bear and a husky engaging playfully at a snowy outpost in northern Canada.) Stuart Brown, president of the National Institute for Play, was s\n",
      "\n",
      "--- Example 3 ---\n",
      "How do you get HIV?\n",
      "HIV can be passed on when infected bodily fluid, such as blood or semen, is passed into an uninfected person. Semen is the liquid which is released from a man's penis during sex which carries sperm. It can be infected with HIV or AIDS when someone is HIV positive or is carrying the AIDS virus. This can happen during unprotected sex. For example when two people have sex without using a condom when one partner is already infected, or between drug users who inject and share need\n",
      "\n",
      "--- Example 4 ---\n",
      "CTComms sends on average 2 million emails monthly on behalf of over 125 different charities and not for profits.\n",
      "Take the complexity of technology and stir in the complexity of the legal system and what do you get? Software licenses! If you've ever attempted to read one you know how true this is, but you have to know a little about software licensing even if you can't parse all of the fine print.\n",
      "By: Chris Peters\n",
      "March 10, 2009\n",
      "A software license is an agreement between you and the owner of a pr\n",
      "\n",
      "--- Example 5 ---\n",
      "Hold the salt: UCLA engineers develop revolutionary new desalination membrane\n",
      "Process uses atmospheric pressure plasma to create filtering 'brush layer'\n",
      "Desalination can become more economical and used as a viable alternate water resource.\n",
      "By Wileen Wong Kromhout\n",
      "Originally published in UCLA Newsroom\n",
      "Researchers from the UCLA Henry Samueli School of Engineering and Applied Science have unveiled a new class of reverse-osmosis membranes for desalination that resist the clogging which typically occ\n"
     ]
    }
   ],
   "source": [
    "# Load a sample of the FineWeb dataset\n",
    "# We'll use a smaller 10B token sample for demonstration\n",
    "fineweb_dataset = load_dataset(\"HuggingFaceFW/fineweb-edu\", \"sample-10BT\", streaming=True, split='train')\n",
    "\n",
    "print(\"--- FineWeb Dataset Examples ---\")\n",
    "for i, example in enumerate(iter(fineweb_dataset.take(5))):\n",
    "    print(f\"\\n--- Example {i+1} ---\")\n",
    "    print(example['text'][:500])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b8620b8",
   "metadata": {},
   "source": [
    "### Conclusion: Quality Over Quantity\n",
    "\n",
    "Comparing the raw C4 examples with the FineWeb examples, the difference is clear. The FineWeb text is much cleaner, reads more like natural prose, and is free of the distracting artifacts common in raw web data.\n",
    "\n",
    "However, extending to a production pipeline is not as straightforward. Lot of nuances go into the tuning of hyperparameters at that scale. \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llms-from-scratch (3.12.0)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
